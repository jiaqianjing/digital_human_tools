import gradio as gr
import os
import re
from dotenv import load_dotenv
from voice_clone import VoiceClone
from voice2text import AudioTranscriber
from split_vedio2audio import VideoAudioSplitter
from voice_generate import VoiceGenerator
import sys

# æ£€æŸ¥.envæ–‡ä»¶æ˜¯å¦å­˜åœ¨
if not os.path.exists('.env'):
    print("\né”™è¯¯ï¼šç¼ºå°‘ .env æ–‡ä»¶ï¼")
    print("è¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤è®¾ç½®ï¼š")
    print("1. å¤åˆ¶ .env.example æ–‡ä»¶å¹¶é‡å‘½åä¸º .env")
    print("2. åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æ‚¨çš„ SILICONFLOW_API_KEY")
    print("3. é‡æ–°è¿è¡Œç¨‹åº\n")
    sys.exit(1)

# åŠ è½½ç¯å¢ƒå˜é‡
load_dotenv()

# æ£€æŸ¥å¿…è¦çš„ç¯å¢ƒå˜é‡
SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")
if not SILICONFLOW_API_KEY:
    print("\né”™è¯¯ï¼šSILICONFLOW_API_KEY æœªè®¾ç½®ï¼")
    print("è¯·åœ¨ .env æ–‡ä»¶ä¸­è®¾ç½®æœ‰æ•ˆçš„ SILICONFLOW_API_KEY")
    print("å¦‚æœæ‚¨è¿˜æ²¡æœ‰ API å¯†é’¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜è·å–\n")
    sys.exit(1)

# åˆå§‹åŒ–æœåŠ¡
voice_clone = VoiceClone(SILICONFLOW_API_KEY)
transcriber = AudioTranscriber(SILICONFLOW_API_KEY)
video_splitter = VideoAudioSplitter()
voice_generator = VoiceGenerator(SILICONFLOW_API_KEY)

# å®šä¹‰å¯ç”¨çš„æ¨¡å‹
AVAILABLE_MODELS = {
    "CosyVoice2": "FunAudioLLM/CosyVoice2-0.5B",
    "Fish Speech": "fishaudio/fish-speech-1.5",
    "GPT-SoVITS": "RVC-Boss/GPT-SoVITS"
}

# å®šä¹‰å†…ç½®å£°éŸ³
built_in_voices = ["alex", "anna", "bella", "benjamin", "charles", "claire", "david", "diana"]

def validate_voice_id(voice_id):
    """éªŒè¯å…‹éš†éŸ³è‰²IDæ˜¯å¦ç¬¦åˆè¦æ±‚"""
    if not voice_id:
        return False, "éŸ³è‰²IDä¸èƒ½ä¸ºç©º"
    if len(voice_id) > 64:
        return False, "éŸ³è‰²IDé•¿åº¦ä¸èƒ½è¶…è¿‡64ä¸ªå­—ç¬¦"
    if not re.match(r'^[a-zA-Z0-9_-]+$', voice_id):
        return False, "éŸ³è‰²IDåªèƒ½åŒ…å«å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦"
    return True, "éªŒè¯é€šè¿‡"

def process_voice_clone(audio_file, reference_text, target_text, model_choice, voice_id):
    """å¤„ç†è¯­éŸ³å…‹éš†è¯·æ±‚"""
    if not audio_file or not reference_text or not target_text:
        return "è¯·ç¡®ä¿æ‰€æœ‰å¿…å¡«å­—æ®µéƒ½å·²å¡«å†™", None

    # éªŒè¯voice_id
    is_valid, message = validate_voice_id(voice_id)
    if not is_valid:
        return message, None

    try:
        # ä¸Šä¼ å‚è€ƒéŸ³é¢‘
        model_id = AVAILABLE_MODELS[model_choice]
        print(f"ä¸Šä¼ è¯­éŸ³æ–‡ä»¶: {audio_file}")
        result = voice_clone.upload_voice_base64(
            audio_file,
            voice_id,
            model_id,
            reference_text
        )

        if not result or 'uri' not in result:
            return "ä¸Šä¼ éŸ³é¢‘å¤±è´¥", None

        voice_uri = result['uri']

        # ç”Ÿæˆè¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        output_dir = os.path.join("outputs", model_choice)
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"output_{voice_id}.wav")

        # ç”Ÿæˆå…‹éš†è¯­éŸ³
        voice_clone.speech(
            target_text,
            voice=voice_uri,
            model_id=model_id,
            speech_file_path=output_path
        )

        return "è¯­éŸ³å…‹éš†æˆåŠŸå®Œæˆï¼", output_path

    except Exception as e:
        return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", None

def transcribe_audio(audio_file):
    """å¤„ç†è¯­éŸ³è½¬æ–‡å­—è¯·æ±‚"""
    if not audio_file:
        return "è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"

    try:
        print(audio_file)  # audio_file is already a path string
        result = transcriber.transcriptions(audio_file)
        return result.get('text', 'è½¬å†™å¤±è´¥')
    except Exception as e:
        return f"è½¬å†™è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

def split_video_audio(video_file, start_time=None, duration=None):
    """å¤„ç†è§†é¢‘åˆ†ç¦»éŸ³é¢‘è¯·æ±‚"""
    if not video_file:
        return "è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶", None

    try:
        # å¤„ç†è§†é¢‘åˆ†ç¦»
        output_path = video_splitter.split_video_to_audio(
            video_file,
            start_time,
            duration
        )
        return "éŸ³é¢‘æå–æˆåŠŸï¼", output_path
    except Exception as e:
        return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", None

def generate_speech(text, model_choice, voice, speed, gain, response_format, sample_rate):
    """å¤„ç†è¯­éŸ³åˆæˆè¯·æ±‚"""
    if not text:
        return "è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬", None
    
    try:
        # ç”Ÿæˆè¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        output_dir = "outputs/generated"
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"generated_{os.urandom(4).hex()}.wav")
        
        # ç”Ÿæˆè¯­éŸ³
        model_id = AVAILABLE_MODELS[model_choice]
        speech_data = voice_generator.create_speech(
            text,
            model=model_id,
            voice=voice,
            speed=speed,
            gain=gain,
            response_format=response_format,
            sample_rate=sample_rate
        )
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        with open(output_path, "wb") as f:
            f.write(speech_data)
            
        return "è¯­éŸ³åˆæˆæˆåŠŸï¼", output_path
    except Exception as e:
        return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", None

def refresh_voice_list():
    """åˆ·æ–°è¯­éŸ³åˆ—è¡¨"""
    return gr.Dropdown(choices=voice_generator.get_voice_list())

def delete_voice(voice):
    """åˆ é™¤è¯­éŸ³"""
    if not voice:
        return "è¯·é€‰æ‹©è¦åˆ é™¤çš„è¯­éŸ³", None
    
    try:
        voice_uri = voice.split(':', 1)[-1]
        result = voice_generator.delete_voice(voice_uri)
        print("åˆ é™¤ç»“æœï¼š", result)
        if result == "success":
            return "è¯­éŸ³åˆ é™¤æˆåŠŸï¼", gr.Dropdown(choices=voice_generator.get_voice_list())
        else:
            return f"åˆ é™¤å¤±è´¥ï¼š{result.get('message', 'æœªçŸ¥é”™è¯¯')}", None
    except Exception as e:
        return f"åˆ é™¤è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", None

def process_voice_clone_and_refresh(audio_file, reference_text, target_text, model_choice, voice_id):
    """å¤„ç†è¯­éŸ³å…‹éš†å¹¶åˆ·æ–°éŸ³è‰²åˆ—è¡¨"""
    status, audio = process_voice_clone(audio_file, reference_text, target_text, model_choice, voice_id)
    # æ— è®ºæˆåŠŸä¸å¦éƒ½åˆ·æ–°åˆ—è¡¨ï¼Œå› ä¸ºå¯èƒ½æœ‰å…¶ä»–ç”¨æˆ·æ·»åŠ äº†æ–°éŸ³è‰²
    return status, audio, gr.Dropdown(choices=built_in_voices + voice_generator.get_voice_list())

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="æ•°å­—äººå·¥å…·åŒ…") as demo:
    gr.Markdown("# ğŸ¤ æ•°å­—äººå·¥å…·åŒ…")

    with gr.Tabs():
        # è§†é¢‘åˆ†ç¦»éŸ³é¢‘æ ‡ç­¾é¡µ
        with gr.Tab("è§†é¢‘åˆ†ç¦»éŸ³é¢‘"):
            gr.Markdown("### è§†é¢‘åˆ†ç¦»éŸ³é¢‘\n\n* å°† mp4 æ ¼å¼çš„è§†é¢‘æ–‡ä»¶è½¬æˆéŸ³é¢‘æ–‡ä»¶ï¼Œæ”¯æŒè§†é¢‘æ–‡ä»¶çš„å¼€å§‹æ—¶é—´ã€æŒç»­æ—¶é—´åˆ†ç¦»éŸ³é¢‘\n* ä½¿ç”¨ffmpegåˆ†ç¦»éŸ³é¢‘ï¼šffmpeg -ss å¼€å§‹æ—¶é—´ -t æŒç»­æ—¶é—´ -i è§†é¢‘æ–‡ä»¶ -code:a copy æå–çš„éŸ³é¢‘æ–‡ä»¶")
            with gr.Row():
                with gr.Column():
                    video_input = gr.Video(label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
                    start_time = gr.Textbox(
                        label="å¼€å§‹æ—¶é—´ï¼ˆæ ¼å¼ï¼šHH:MM:SSï¼Œä¾‹å¦‚ 00:00:00ï¼‰",
                        value="00:00:00",
                        placeholder="00:00:00"
                    )
                    duration = gr.Textbox(
                        label="æŒç»­æ—¶é—´ï¼ˆæ ¼å¼ï¼šHH:MM:SSï¼Œä¾‹å¦‚ 00:00:30ï¼‰",
                        value="00:00:30",
                        placeholder="00:00:00"
                    )
                    split_btn = gr.Button("å¼€å§‹åˆ†ç¦»", variant="primary")

                with gr.Column():
                    split_status = gr.Textbox(label="å¤„ç†çŠ¶æ€")
                    output_audio_file = gr.Audio(label="æå–çš„éŸ³é¢‘")
                    send_to_clone_btn = gr.Button("å‘é€åˆ°è¯­éŸ³å…‹éš†", variant="secondary")

        # è¯­éŸ³è½¬å†™æ ‡ç­¾é¡µ
        with gr.Tab("è¯­éŸ³è½¬å†™"):
            gr.Markdown("### è¯­éŸ³è½¬å†™\n\n* é€‰æ‹©æ¨¡å‹ï¼šFunAudioLLM/SenseVoiceSmall")
            audio_input_transcribe = gr.Audio(label="ä¸Šä¼ è¦è½¬å†™çš„éŸ³é¢‘", type="filepath")
            transcribe_btn = gr.Button("å¼€å§‹è½¬å†™", variant="primary")
            transcription_output = gr.Textbox(label="è½¬å†™ç»“æœ")
            
        # è¯­éŸ³å…‹éš†æ ‡ç­¾é¡µ
        with gr.Tab("è¯­éŸ³å…‹éš†"):
            gr.Markdown("### è¯­éŸ³å…‹éš†\n\n* å…‹éš†éŸ³è‰²ï¼šä¸Šä¼ éŸ³é¢‘ä»¥åŠå¯¹åº”çš„è½¬å½•æ–‡æœ¬ï¼Œç”Ÿæˆã€å…‹éš†éŸ³è‰²IDã€‘\n* æ ¹æ®åˆ›å»ºçš„éŸ³è‰²ï¼Œæ–‡å­—è½¬éŸ³é¢‘")
            with gr.Row():
                with gr.Column():
                    audio_input = gr.Audio(label="ä¸Šä¼ å‚è€ƒéŸ³é¢‘", type="filepath")
                    with gr.Row():
                        reference_text = gr.Textbox(label="å‚è€ƒéŸ³é¢‘æ–‡æœ¬", placeholder="è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬å†…å®¹ï¼ˆå¯ç‚¹å‡»æ—è¾¹çš„ã€è½¬å†™éŸ³é¢‘ã€‘æŒ‰é’®åç¼–è¾‘ï¼‰", scale=4)
                        transcribe_ref_btn = gr.Button("è½¬å†™éŸ³é¢‘", scale=1, variant="primary")
                    target_text = gr.Textbox(label="ç›®æ ‡ç”Ÿæˆæ–‡æœ¬", placeholder="è¯·è¾“å…¥è¦ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹")
                    model_choice = gr.Dropdown(
                        choices=list(AVAILABLE_MODELS.keys()),
                        label="é€‰æ‹©æ¨¡å‹",
                        value="CosyVoice2"
                    )
                    voice_id = gr.Textbox(
                        label="å…‹éš†éŸ³è‰²IDï¼ˆç”¨æˆ·å¯ä»¥è‡ªå·±å®šä¹‰ï¼Œonly letters and digits and _ and - are supported. Should not exceed 64 charsï¼‰",
                        value="voice_" + os.urandom(4).hex(),
                        placeholder="è¯·è¾“å…¥å”¯ä¸€çš„å£°éŸ³ID"
                    )
                    clone_btn = gr.Button("å¼€å§‹å…‹éš†", variant="primary")

                with gr.Column():
                    output_message = gr.Textbox(label="å¤„ç†çŠ¶æ€")
                    output_audio = gr.Audio(label="ç”Ÿæˆçš„éŸ³é¢‘")

        # è¯­éŸ³åˆæˆæ ‡ç­¾é¡µ
        with gr.Tab("è¯­éŸ³åˆæˆ"):
            gr.Markdown("### è¯­éŸ³åˆæˆ\n\n* å†…ç½®éŸ³è‰²ï¼šalex, anna, bella, benjamin, charles, claire, david, diana\n* å…‹éš†éŸ³è‰²ï¼šä»ã€è¯­éŸ³å…‹éš†ã€‘åˆ›å»ºçš„ã€å…‹éš†éŸ³è‰²IDã€‘ä½œä¸ºå‰ç¼€åŒºåˆ†\n* æ ¹æ®ä»¥ä¸Šä¸¤ç§é€‰æ‹©ï¼Œæ–‡å­—è½¬éŸ³é¢‘")
            with gr.Row():
                with gr.Column():
                    text_input = gr.Textbox(
                        label="è¾“å…¥æ–‡æœ¬",
                        placeholder="è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬å†…å®¹",
                        lines=5
                    )
                    model_select = gr.Dropdown(
                        choices=list(AVAILABLE_MODELS.keys()),
                        label="é€‰æ‹©æ¨¡å‹",
                        interactive=True,
                        value="CosyVoice2"
                    )
                    with gr.Row():
                        voice_select = gr.Dropdown(
                            choices=built_in_voices + voice_generator.get_voice_list(),
                            label="é€‰æ‹©éŸ³è‰²ï¼ˆå†…ç½®éŸ³è‰²ï¼šalex, anna, bella, benjamin, charles, claire, david, dianaï¼Œå…‹éš†éŸ³è‰²ï¼šä»ã€è¯­éŸ³å…‹éš†ã€‘åˆ›å»ºçš„ã€å…‹éš†éŸ³è‰²IDã€‘ä½œä¸ºå‰ç¼€åŒºåˆ†ï¼‰",
                            interactive=True,
                            value=built_in_voices[0],
                            scale=4
                        )
                        with gr.Column(scale=1):
                            refresh_voice_select_btn = gr.Button("ğŸ”„ åˆ·æ–°éŸ³è‰²åˆ—è¡¨", variant="secondary")
                            delete_voice_btn = gr.Button("ğŸ—‘ï¸ åˆ é™¤éŸ³è‰²", variant="primary")
                    voice_manage_status = gr.Textbox(label="éŸ³è‰²ç®¡ç†çŠ¶æ€", visible=True)
                    with gr.Row():
                        response_format = gr.Dropdown(
                            choices=["mp3", "opus", "wav", "pcm"],
                            label="è¾“å‡ºæ ¼å¼",
                            value="wav"
                        )
                        sample_rate = gr.Dropdown(
                            choices=[8000, 16000, 24000, 32000, 44100, 48000],
                            info="opus: Supports 48000 Hz. wav, pcm: Supports 8000, 16000, 24000, 32000, 44100 Hz, with a default of 44100 Hz. mp3: Supports 32000, 44100 Hz, with a default of 44100 Hz.",
                            label="é‡‡æ ·ç‡",
                            value=44100
                        )
                        speed_slider = gr.Slider(
                            minimum=0.25,
                            maximum=4.0,
                            value=1.0,
                            step=0.1,
                            label="è¯­é€Ÿ"
                        )
                        gain_slider = gr.Slider(
                            minimum=-20,
                            maximum=20,
                            value=0,
                            step=1,
                            label="éŸ³é‡å¢ç›Š"
                        )
                    generate_btn = gr.Button("å¼€å§‹åˆæˆ", variant="primary")

                with gr.Column():
                    generate_status = gr.Textbox(label="å¤„ç†çŠ¶æ€")
                    generated_audio = gr.Audio(label="åˆæˆçš„éŸ³é¢‘")

    # ç»‘å®šäº‹ä»¶
    def send_to_voice_clone(audio):
        """å°†éŸ³é¢‘å‘é€åˆ°è¯­éŸ³å…‹éš†æ ‡ç­¾é¡µ"""
        if audio is None:
            return None
        return audio

    send_to_clone_btn.click(
        send_to_voice_clone,
        inputs=[output_audio_file],
        outputs=[audio_input]
    )

    transcribe_ref_btn.click(
        transcribe_audio,
        inputs=[audio_input],
        outputs=[reference_text]
    )

    # å®šä¹‰åˆ·æ–°éŸ³è‰²åˆ—è¡¨å‡½æ•°
    def refresh_voice_select():
        return gr.Dropdown(choices=built_in_voices + voice_generator.get_voice_list())

    # å®šä¹‰åˆ é™¤å¹¶åˆ·æ–°éŸ³è‰²çš„å‡½æ•°
    def delete_and_refresh_voice(voice):
        # æ£€æŸ¥æ˜¯å¦æ˜¯å†…ç½®éŸ³è‰²
        if voice in built_in_voices:
            return "å†…ç½®éŸ³è‰²æ— æ³•åˆ é™¤ï¼", gr.Dropdown(choices=built_in_voices + voice_generator.get_voice_list()), "å†…ç½®éŸ³è‰²æ— æ³•åˆ é™¤ï¼"
        status, _ = delete_voice(voice)
        return status, gr.Dropdown(choices=built_in_voices + voice_generator.get_voice_list()), status

    # ç»‘å®šéŸ³è‰²åˆ—è¡¨åˆ·æ–°äº‹ä»¶
    refresh_voice_select_btn.click(
        refresh_voice_select,
        outputs=[voice_select]
    )

    # ç»‘å®šåˆ é™¤éŸ³è‰²äº‹ä»¶
    delete_voice_btn.click(
        delete_and_refresh_voice,
        inputs=[voice_select],
        outputs=[voice_manage_status, voice_select, voice_manage_status]
    )

    # åœ¨æˆåŠŸå…‹éš†åä¹Ÿåˆ·æ–°éŸ³è‰²åˆ—è¡¨
    clone_btn.click(
        process_voice_clone_and_refresh,
        inputs=[audio_input, reference_text, target_text, model_choice, voice_id],
        outputs=[output_message, output_audio, voice_select]
    )

    transcribe_btn.click(
        transcribe_audio,
        inputs=[audio_input_transcribe],
        outputs=[transcription_output]
    )

    split_btn.click(
        split_video_audio,
        inputs=[video_input, start_time, duration],
        outputs=[split_status, output_audio_file]
    )

    generate_btn.click(
        generate_speech,
        inputs=[text_input, model_select, voice_select, speed_slider, gain_slider, response_format, sample_rate],
        outputs=[generate_status, generated_audio]
    )

if __name__ == "__main__":
    demo.launch(share=True)
