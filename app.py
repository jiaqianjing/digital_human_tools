import gradio as gr
import os
from dotenv import load_dotenv
from voice_clone import VoiceClone
from voice2text import AudioTranscriber
from split_vedio2audio import VideoAudioSplitter
from voice_generate import VoiceGenerator

load_dotenv()

# åˆå§‹åŒ– API key
SILICONFLOW_API_KEY = os.getenv("SILICONFLOW_API_KEY")
voice_clone = VoiceClone(SILICONFLOW_API_KEY)
transcriber = AudioTranscriber(SILICONFLOW_API_KEY)
video_splitter = VideoAudioSplitter()
voice_generator = VoiceGenerator(SILICONFLOW_API_KEY)

# å®šä¹‰å¯ç”¨çš„æ¨¡å‹
AVAILABLE_MODELS = {
    "CosyVoice2": "FunAudioLLM/CosyVoice2-0.5B",
    "Fish Speech": "fishaudio/fish-speech-1.5",
    "GPT-SoVITS": "RVC-Boss/GPT-SoVITS"
}

# å®šä¹‰å†…ç½®å£°éŸ³
built_in_voices = ["alex", "anna", "bella", "benjamin", "charles", "claire", "david", "diana"]

def process_voice_clone(audio_file, reference_text, target_text, model_choice, voice_id):
    """å¤„ç†è¯­éŸ³å…‹éš†è¯·æ±‚"""
    if not audio_file or not reference_text or not target_text:
        return "è¯·ç¡®ä¿æ‰€æœ‰å¿…å¡«å­—æ®µéƒ½å·²å¡«å†™", None

    try:
        # ä¸Šä¼ å‚è€ƒéŸ³é¢‘
        model_id = AVAILABLE_MODELS[model_choice]
        result = voice_clone.upload_voice_base64(
            audio_file.name,
            voice_id,
            model_id,
            reference_text
        )

        if not result or 'uri' not in result:
            return "ä¸Šä¼ éŸ³é¢‘å¤±è´¥", None

        voice_uri = result['uri']

        # ç”Ÿæˆè¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        output_dir = os.path.join("outputs", model_choice)
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"output_{voice_id}.wav")

        # ç”Ÿæˆå…‹éš†è¯­éŸ³
        voice_clone.speech(
            target_text,
            voice=voice_uri,
            model_id=model_id,
            speech_file_path=output_path
        )

        return "è¯­éŸ³å…‹éš†æˆåŠŸå®Œæˆï¼", output_path

    except Exception as e:
        return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", None

def transcribe_audio(audio_file):
    """å¤„ç†è¯­éŸ³è½¬æ–‡å­—è¯·æ±‚"""
    if not audio_file:
        return "è¯·ä¸Šä¼ éŸ³é¢‘æ–‡ä»¶"

    try:
        print(audio_file)  # audio_file is already a path string
        result = transcriber.transcriptions(audio_file)
        return result.get('text', 'è½¬å†™å¤±è´¥')
    except Exception as e:
        return f"è½¬å†™è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}"

def split_video_audio(video_file, start_time=None, duration=None):
    """å¤„ç†è§†é¢‘åˆ†ç¦»éŸ³é¢‘è¯·æ±‚"""
    if not video_file:
        return "è¯·ä¸Šä¼ è§†é¢‘æ–‡ä»¶", None

    try:
        # å¤„ç†è§†é¢‘åˆ†ç¦»
        output_path = video_splitter.split_video_to_audio(
            video_file,
            start_time,
            duration
        )
        return "éŸ³é¢‘æå–æˆåŠŸï¼", output_path
    except Exception as e:
        return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", None

def generate_speech(text, model_choice, voice, speed, gain, response_format, sample_rate):
    """å¤„ç†è¯­éŸ³åˆæˆè¯·æ±‚"""
    if not text:
        return "è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬", None
    
    try:
        # ç”Ÿæˆè¾“å‡ºéŸ³é¢‘æ–‡ä»¶è·¯å¾„
        output_dir = "outputs/generated"
        os.makedirs(output_dir, exist_ok=True)
        output_path = os.path.join(output_dir, f"generated_{os.urandom(4).hex()}.wav")
        
        # ç”Ÿæˆè¯­éŸ³
        model_id = AVAILABLE_MODELS[model_choice]
        speech_data = voice_generator.create_speech(
            text,
            model=model_id,
            voice=voice,
            speed=speed,
            gain=gain,
            response_format=response_format,
            sample_rate=sample_rate
        )
        
        # ä¿å­˜éŸ³é¢‘æ–‡ä»¶
        with open(output_path, "wb") as f:
            f.write(speech_data)
            
        return "è¯­éŸ³åˆæˆæˆåŠŸï¼", output_path
    except Exception as e:
        return f"å¤„ç†è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", None

def refresh_voice_list():
    """åˆ·æ–°è¯­éŸ³åˆ—è¡¨"""
    return gr.Dropdown(choices=voice_generator.get_voice_list())

def delete_voice(voice):
    """åˆ é™¤è¯­éŸ³"""
    if not voice:
        return "è¯·é€‰æ‹©è¦åˆ é™¤çš„è¯­éŸ³", None
    
    try:
        voice_uri = voice.split(':', 1)[-1]
        result = voice_generator.delete_voice(voice_uri)
        print("åˆ é™¤ç»“æœï¼š", result)
        if result == "success":
            return "è¯­éŸ³åˆ é™¤æˆåŠŸï¼", gr.Dropdown(choices=voice_generator.get_voice_list())
        else:
            return f"åˆ é™¤å¤±è´¥ï¼š{result.get('message', 'æœªçŸ¥é”™è¯¯')}", None
    except Exception as e:
        return f"åˆ é™¤è¿‡ç¨‹ä¸­å‡ºé”™: {str(e)}", None

# åˆ›å»º Gradio ç•Œé¢
with gr.Blocks(title="æ•°å­—äººå·¥å…·åŒ…") as demo:
    gr.Markdown("# ğŸ¤ æ•°å­—äººå·¥å…·åŒ…")

    with gr.Tabs():
        # è§†é¢‘åˆ†ç¦»éŸ³é¢‘æ ‡ç­¾é¡µ
        with gr.Tab("è§†é¢‘åˆ†ç¦»éŸ³é¢‘"):
            with gr.Row():
                with gr.Column():
                    video_input = gr.Video(label="ä¸Šä¼ è§†é¢‘æ–‡ä»¶")
                    start_time = gr.Textbox(
                        label="å¼€å§‹æ—¶é—´ï¼ˆæ ¼å¼ï¼šHH:MM:SSï¼Œä¾‹å¦‚ 00:01:30ï¼‰",
                        placeholder="00:00:00"
                    )
                    duration = gr.Textbox(
                        label="æŒç»­æ—¶é—´ï¼ˆæ ¼å¼ï¼šHH:MM:SSï¼Œä¾‹å¦‚ 00:00:30ï¼‰",
                        placeholder="00:00:00"
                    )
                    split_btn = gr.Button("å¼€å§‹åˆ†ç¦»", variant="primary")

                with gr.Column():
                    split_status = gr.Textbox(label="å¤„ç†çŠ¶æ€")
                    output_audio_file = gr.Audio(label="æå–çš„éŸ³é¢‘")

        # è¯­éŸ³è½¬å†™æ ‡ç­¾é¡µ
        with gr.Tab("è¯­éŸ³è½¬å†™"):
            audio_input_transcribe = gr.Audio(label="ä¸Šä¼ è¦è½¬å†™çš„éŸ³é¢‘", type="filepath")
            transcribe_btn = gr.Button("å¼€å§‹è½¬å†™", variant="primary")
            transcription_output = gr.Textbox(label="è½¬å†™ç»“æœ")
            
        # è¯­éŸ³å…‹éš†æ ‡ç­¾é¡µ
        with gr.Tab("è¯­éŸ³å…‹éš†"):
            with gr.Row():
                with gr.Column():
                    audio_input = gr.Audio(label="ä¸Šä¼ å‚è€ƒéŸ³é¢‘", type="filepath")
                    reference_text = gr.Textbox(label="å‚è€ƒéŸ³é¢‘æ–‡æœ¬", placeholder="è¯·è¾“å…¥å‚è€ƒéŸ³é¢‘å¯¹åº”çš„æ–‡æœ¬å†…å®¹")
                    target_text = gr.Textbox(label="ç›®æ ‡ç”Ÿæˆæ–‡æœ¬", placeholder="è¯·è¾“å…¥è¦ç”Ÿæˆçš„æ–‡æœ¬å†…å®¹")
                    model_choice = gr.Dropdown(
                        choices=list(AVAILABLE_MODELS.keys()),
                        label="é€‰æ‹©æ¨¡å‹",
                        value="CosyVoice2"
                    )
                    voice_id = gr.Textbox(
                        label="å£°éŸ³ID",
                        value="voice_" + os.urandom(4).hex(),
                        placeholder="è¯·è¾“å…¥å”¯ä¸€çš„å£°éŸ³ID"
                    )
                    clone_btn = gr.Button("å¼€å§‹å…‹éš†", variant="primary")

                with gr.Column():
                    output_message = gr.Textbox(label="å¤„ç†çŠ¶æ€")
                    output_audio = gr.Audio(label="ç”Ÿæˆçš„éŸ³é¢‘")

        # è¯­éŸ³åˆæˆæ ‡ç­¾é¡µ
        with gr.Tab("è¯­éŸ³åˆæˆ"):
            with gr.Row():
                with gr.Column():
                    text_input = gr.Textbox(
                        label="è¾“å…¥æ–‡æœ¬",
                        placeholder="è¯·è¾“å…¥è¦åˆæˆçš„æ–‡æœ¬å†…å®¹",
                        lines=5
                    )
                    model_select = gr.Dropdown(
                        choices=list(AVAILABLE_MODELS.keys()),
                        label="é€‰æ‹©æ¨¡å‹",
                        interactive=True,
                        value="CosyVoice2"
                    )
                    voice_select = gr.Dropdown(
                        choices=built_in_voices + voice_generator.get_voice_list(),
                        label="é€‰æ‹©å£°éŸ³",
                        interactive=True,
                        value=built_in_voices[0]
                    )
                    with gr.Row():
                        response_format = gr.Dropdown(
                            choices=["mp3", "opus", "wav", "pcm"],
                            label="è¾“å‡ºæ ¼å¼",
                            value="wav"
                        )
                        sample_rate = gr.Dropdown(
                            choices=[8000, 16000, 24000, 32000, 44100, 48000],
                            info="opus: Supports 48000 Hz. wav, pcm: Supports 8000, 16000, 24000, 32000, 44100 Hz, with a default of 44100 Hz. mp3: Supports 32000, 44100 Hz, with a default of 44100 Hz.",
                            label="é‡‡æ ·ç‡",
                            value=44100
                        )
                        speed_slider = gr.Slider(
                            minimum=0.25,
                            maximum=4.0,
                            value=1.0,
                            step=0.1,
                            label="è¯­é€Ÿ"
                        )
                        gain_slider = gr.Slider(
                            minimum=-20,
                            maximum=20,
                            value=0,
                            step=1,
                            label="éŸ³é‡å¢ç›Š"
                        )
                    generate_btn = gr.Button("å¼€å§‹åˆæˆ", variant="primary")

                with gr.Column():
                    generate_status = gr.Textbox(label="å¤„ç†çŠ¶æ€")
                    generated_audio = gr.Audio(label="åˆæˆçš„éŸ³é¢‘")

        # è¯­éŸ³ç®¡ç†æ ‡ç­¾é¡µ
        with gr.Tab("è¯­éŸ³ç®¡ç†"):
            with gr.Row():
                with gr.Column():
                    voice_list = gr.Dropdown(
                        choices=voice_generator.get_voice_list(),
                        label="é€‰æ‹©è¦åˆ é™¤çš„è¯­éŸ³",
                        interactive=True
                    )
                    with gr.Row():
                        refresh_btn = gr.Button("åˆ·æ–°åˆ—è¡¨", variant="secondary")
                        delete_btn = gr.Button("åˆ é™¤è¯­éŸ³", variant="primary")
                with gr.Column():
                    manage_status = gr.Textbox(label="å¤„ç†çŠ¶æ€")

    # ç»‘å®šäº‹ä»¶
    clone_btn.click(
        process_voice_clone,
        inputs=[audio_input, reference_text, target_text, model_choice, voice_id],
        outputs=[output_message, output_audio]
    )

    transcribe_btn.click(
        transcribe_audio,
        inputs=[audio_input_transcribe],
        outputs=[transcription_output]
    )

    split_btn.click(
        split_video_audio,
        inputs=[video_input, start_time, duration],
        outputs=[split_status, output_audio_file]
    )

    generate_btn.click(
        generate_speech,
        inputs=[text_input, model_select, voice_select, speed_slider, gain_slider, response_format, sample_rate],
        outputs=[generate_status, generated_audio]
    )

    refresh_btn.click(
        refresh_voice_list,
        outputs=[voice_list]
    )

    delete_btn.click(
        delete_voice,
        inputs=[voice_list],
        outputs=[manage_status, voice_list]
    )

if __name__ == "__main__":
    demo.launch(share=True)
